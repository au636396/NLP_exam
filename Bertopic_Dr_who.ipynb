{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ff8cd465-f19b-4a53-9e07-ea7b61e3a158"},"outputs":[],"source":["# setup\n","! pip install bertopic"],"id":"ff8cd465-f19b-4a53-9e07-ea7b61e3a158"},{"cell_type":"code","source":["#packages for making the model and setting up the data\n","from bertopic import BERTopic\n","import pandas as pd\n","import os\n","\n","#packages for cleaning\n","import sys  \n","!{sys.executable} -m pip install contractions\n","import contractions  \n","import re  \n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","nltk.download('stopwords')\n","nltk.download('punkt') "],"metadata":{"id":"fjqsyX7L2x6t"},"id":"fjqsyX7L2x6t","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"42e71372-404b-402f-95d3-a2eefb898ec2"},"outputs":[],"source":["#load in the data needed \n","filepath_script = os.path.join(\"Data\",\"all-scripts.csv\")\n","filepath_date = os.path.join(\"Data\",\"all-detailsepisodes.csv\")\n","df_script = pd.read_csv(filepath_script)   # data containing the scripts \n","df_date = pd.read_csv(filepath_date) # data containing the date of releace\n","\n","#merging the two dataframes by episode id\n","df = pd.merge(df_script, df_date, on='episodeid')\n","\n","#removing repeat colunm\n","df = df.drop('doctorid_y', axis=1)"],"id":"42e71372-404b-402f-95d3-a2eefb898ec2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Zonl9gxyl6y"},"outputs":[],"source":["#getting rid of NAs, this also gets rid of things not tagged as talk, to check run: print(df['type'].unique())\n","df = df.dropna()  #319847 rows to 245618 \n","\n","#making a function that removes special characters from the dates\n","def clean_date(x):\n","  x = re.sub(r'[%s]' % re.escape('!\"#$%&\\()*+,-./:;<=>?@©[\\\\]^_`{|}~“…”’'), ' ', x)   #Removes special characters\n","  return x\n","\n","df[\"first_diffusion\"] = df.first_diffusion.apply(clean_date)"],"id":"_Zonl9gxyl6y"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SROn8VmH3Yyx"},"outputs":[],"source":["stop_words = stopwords.words('english')\n","\n","#making a function that cleans the texts and tokenices it with NLTK\n","def clean_text(x):\n","  x = str(x)\n","  x = x.lower()\n","  x = contractions.fix(x)\n","  x = re.sub(r'#[A-Za-z0-9]*', ' ', x)   #removes induvial leters and numbers\n","  tokens = word_tokenize(x)\n","  x = ' '.join([w for w in tokens if not w.lower() in stop_words])\n","  x = re.sub(r'[%s]' % re.escape('!\"#$%&\\()*+,-./:;<=>?@©[\\\\]^_`{|}~“…”’'), ' ', x)   #removes spetial charecteres\n","  x = re.sub(r'[%s]' % re.escape(\"'\"), ' ', x)  #removes '\n","  x = re.sub(r'\\d+', ' ', x)     #removes Unicode character category [Nd]\n","  x = re.sub(r'\\n+', ' ', x)     #removes new lines\n","  x = re.sub(r'\\s{2,}', ' ', x)    #removes Unicode whitespace characters\n","  shortword = re.compile(r'\\W*\\b\\w{1,2}\\b') #removes words with only two letters\n","  x = shortword.sub('', x)\n","  return x\n","\n","df['clean_text'] = df.text.apply(clean_text)"],"id":"SROn8VmH3Yyx"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bb01958a-28d6-4737-8142-992a2454bc1b"},"outputs":[],"source":["# put the data used for the model in list form, this is also needed for making a timeline\n","script = df.clean_text.to_list() \n","date = df.first_diffusion.to_list()"],"id":"bb01958a-28d6-4737-8142-992a2454bc1b"},{"cell_type":"markdown","source":["Code for setting up a model:"],"metadata":{"id":"oBm6eePhGXV4"},"id":"oBm6eePhGXV4"},{"cell_type":"code","source":["topic_model= BERTopic(language = \"english\")\n","topics, probs = topic_model.fit_transform(script)"],"metadata":{"id":"EZRKsEr9fMSW"},"id":"EZRKsEr9fMSW","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#reducing the number of topics to make it easier to work with:\n","topic_model.reduce_topics(script, nr_topics=1000)   "],"metadata":{"id":"AGudB2o788gc"},"id":"AGudB2o788gc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#getting an overview of the topics generated\n","topic_model.get_topic_info() "],"metadata":{"id":"irTfPj54NsPa"},"id":"irTfPj54NsPa","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Different visualisations:"],"metadata":{"id":"hJR84a7hNb3M"},"id":"hJR84a7hNb3M"},{"cell_type":"code","source":["topic_model.visualize_barchart(title = \"Topic Word Score\")"],"metadata":{"id":"PZB-unE9xNEf"},"id":"PZB-unE9xNEf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualising the topics\n","#topic_model.visualize_topics()"],"metadata":{"id":"e7n3h3xwdX2T"},"id":"e7n3h3xwdX2T","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#topics_over_time = basemodel1.topics_over_time(script, date, nr_bins=20)\n","topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=11) "],"metadata":{"id":"2LVzLCPlFYLY"},"id":"2LVzLCPlFYLY","execution_count":null,"outputs":[]},{"cell_type":"code","source":["#code for finding related topics, here looking fro the word \"war\" :\n","topic_model.find_topics(\"war\", top_n=5) "],"metadata":{"id":"YMAZScfDNMqf"},"id":"YMAZScfDNMqf","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 ","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}